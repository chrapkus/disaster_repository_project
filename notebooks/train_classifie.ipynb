{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb89a4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SzymonGrzebyta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SzymonGrzebyta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SzymonGrzebyta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import multioutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c967161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///../disaster.db')\n",
    "df = pd.read_sql(\"SELECT * FROM disaster\", engine)\n",
    "X = df['message']\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis = 1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2f6d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # lower all text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Normalize text - removing punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    # Tokenize -> slit into list\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words_list = stopwords.words('english')\n",
    "    tokens = [token.strip() for token in tokens if token not in stop_words_list]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmed = [WordNetLemmatizer().lemmatize(token, pos = 'v') for token in tokens]\n",
    "    \n",
    "    # Steaming\n",
    "    stemmed = [PorterStemmer().stem(word) for word in lemmed]\n",
    "\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b004321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    #setting pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', multioutput.MultiOutputClassifier (RandomForestClassifier()))\n",
    "        ])\n",
    "\n",
    "    # fbeta_score scoring object using make_scorer()\n",
    "    scorer = 'f1_weighted'\n",
    "\n",
    "    #model parameters for GridSearchCV\n",
    "    parameters = {  'vect__max_df': (0.3, 0.5),\n",
    "                    'clf__estimator__n_estimators': [10, 5],\n",
    "                    'clf__estimator__min_samples_split': [2, 10]\n",
    "              }\n",
    "    cv = GridSearchCV(pipeline, param_grid= parameters, scoring = scorer, verbose =7, cv = 2)\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cd4b1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "import numpy as np\n",
    "def eval_metrics(ArrayL, ArrayP, col_names):\n",
    "    \"\"\"Evalute metrics of the ML pipeline model\n",
    "    \n",
    "    inputs:\n",
    "    ArrayL: array. Array containing the real labels.\n",
    "    ArrayP: array. Array containing predicted labels.\n",
    "    col_names: list of strings. List containing names for each of the ArrayP fields.\n",
    "       \n",
    "    Returns:\n",
    "    data_metrics: Contains accuracy, precision, recall \n",
    "    and f1 score for a given set of ArrayL and ArrayP labels.\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    # Evaluate metrics for each set of labels\n",
    "    for i in range(len(col_names)):\n",
    "        accuracy = accuracy_score(ArrayL[:, i], ArrayP[:, i])\n",
    "        precision = precision_score(ArrayL[:, i], ArrayP[:, i])\n",
    "        recall = recall_score(ArrayL[:, i], ArrayP[:, i])\n",
    "        f1 = f1_score(ArrayL[:, i], ArrayP[:, i])\n",
    "        \n",
    "        metrics.append([accuracy, precision, recall, f1])\n",
    "    \n",
    "    # store metrics\n",
    "    metrics = np.array(metrics)\n",
    "    data_metrics = pd.DataFrame(data = metrics, index = col_names, columns = ['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "      \n",
    "    return data_metrics    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f3c5e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 1/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=0.3;, score=0.532 total time=  36.4s\n",
      "[CV 2/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=0.3;, score=0.527 total time=  32.3s\n",
      "[CV 1/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=0.5;, score=0.521 total time=  30.8s\n",
      "[CV 2/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, vect__max_df=0.5;, score=0.529 total time=  30.1s\n",
      "[CV 1/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=0.3;, score=0.557 total time=  24.9s\n",
      "[CV 2/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=0.3;, score=0.551 total time=  25.3s\n",
      "[CV 1/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=0.5;, score=0.546 total time=  24.4s\n",
      "[CV 2/2] END clf__estimator__min_samples_split=2, clf__estimator__n_estimators=5, vect__max_df=0.5;, score=0.554 total time=  24.0s\n",
      "[CV 1/2] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, vect__max_df=0.3;, score=0.557 total time=  28.3s\n",
      "[CV 2/2] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, vect__max_df=0.3;, score=0.565 total time=  27.9s\n",
      "[CV 1/2] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, vect__max_df=0.5;, score=0.560 total time=  27.9s\n",
      "[CV 2/2] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, vect__max_df=0.5;, score=0.565 total time=  27.4s\n",
      "[CV 1/2] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=5, vect__max_df=0.3;, score=0.551 total time=  23.1s\n",
      "[CV 2/2] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=5, vect__max_df=0.3;, score=0.551 total time=  22.6s\n",
      "[CV 1/2] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=5, vect__max_df=0.5;, score=0.557 total time=  22.9s\n",
      "[CV 2/2] END clf__estimator__min_samples_split=10, clf__estimator__n_estimators=5, vect__max_df=0.5;, score=0.550 total time=  22.7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        CountVectorizer(tokenizer=<function tokenize at 0x0000016FFB1C4AF0>)),\n",
       "                                       ('tfidf', TfidfTransformer()),\n",
       "                                       ('clf',\n",
       "                                        MultiOutputClassifier(estimator=RandomForestClassifier()))]),\n",
       "             param_grid={'clf__estimator__min_samples_split': [2, 10],\n",
       "                         'clf__estimator__n_estimators': [10, 5],\n",
       "                         'vect__max_df': (0.3, 0.5)},\n",
       "             scoring='f1_weighted', verbose=7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model()\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7a9529",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "add334a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.819707   0.841986  0.940731  0.888624\n",
      "request                 0.893174   0.808850  0.506091  0.622616\n",
      "offer                   0.995565   0.000000  0.000000  0.000000\n",
      "aid_related             0.768222   0.728675  0.702929  0.715570\n",
      "medical_help            0.916699   0.566667  0.114865  0.191011\n",
      "medical_products        0.950058   0.722222  0.094545  0.167203\n",
      "search_and_rescue       0.970112   0.666667  0.109756  0.188482\n",
      "security                0.979946   0.000000  0.000000  0.000000\n",
      "military                0.967991   0.617647  0.120690  0.201923\n",
      "water                   0.957192   0.836842  0.454286  0.588889\n",
      "food                    0.944659   0.830986  0.622144  0.711558\n",
      "shelter                 0.937717   0.814433  0.355056  0.494523\n",
      "clothing                0.988430   0.666667  0.181818  0.285714\n",
      "money                   0.976089   0.750000  0.023810  0.046154\n",
      "missing_people          0.990551   0.000000  0.000000  0.000000\n",
      "refugees                0.966062   0.625000  0.108696  0.185185\n",
      "death                   0.963363   0.695238  0.316017  0.434524\n",
      "other_aid               0.878326   0.532609  0.076923  0.134431\n",
      "infrastructure_related  0.937138   0.250000  0.012579  0.023952\n",
      "transport               0.958157   0.791667  0.082251  0.149020\n",
      "buildings               0.955071   0.738095  0.122530  0.210169\n",
      "electricity             0.981296   0.800000  0.077670  0.141593\n",
      "tools                   0.993830   0.000000  0.000000  0.000000\n",
      "hospitals               0.989587   0.000000  0.000000  0.000000\n",
      "shops                   0.996336   0.000000  0.000000  0.000000\n",
      "aid_centers             0.988430   0.000000  0.000000  0.000000\n",
      "other_infrastructure    0.957000   0.100000  0.004651  0.008889\n",
      "weather_related         0.866371   0.791768  0.692797  0.738983\n",
      "floods                  0.958735   0.912664  0.518610  0.661392\n",
      "storm                   0.936367   0.746575  0.459916  0.569191\n",
      "fire                    0.990359   1.000000  0.019608  0.038462\n",
      "earthquake              0.970690   0.870044  0.809426  0.838641\n",
      "cold                    0.983031   0.666667  0.147368  0.241379\n",
      "other_weather           0.945816   0.407407  0.039855  0.072607\n",
      "direct_report           0.848052   0.728302  0.374757  0.494872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SzymonGrzebyta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SzymonGrzebyta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SzymonGrzebyta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\SzymonGrzebyta\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "col_names = list(Y.columns.values)\n",
    "eval_metrics0 = eval_metrics(np.array(Y_test), Y_pred, col_names)\n",
    "print(eval_metrics0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf4b87c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "request\n",
      "aid_related\n",
      "food\n",
      "direct_report\n"
     ]
    }
   ],
   "source": [
    "mess =np.array(['I am hungry'])\n",
    "sol = model.predict(mess)\n",
    "names = list(Y.columns)\n",
    "for index,x in enumerate(sol[0]):\n",
    "    if x == 1:\n",
    "        print(names[index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32b8a8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'related': 1, 'request': 1, 'offer': 0, 'aid_related': 1, 'medical_help': 0, 'medical_products': 0, 'search_and_rescue': 0, 'security': 0, 'military': 0, 'water': 0, 'food': 1, 'shelter': 0, 'clothing': 0, 'money': 0, 'missing_people': 0, 'refugees': 0, 'death': 0, 'other_aid': 0, 'infrastructure_related': 0, 'transport': 0, 'buildings': 0, 'electricity': 0, 'tools': 0, 'hospitals': 0, 'shops': 0, 'aid_centers': 0, 'other_infrastructure': 0, 'weather_related': 0, 'floods': 0, 'storm': 0, 'fire': 0, 'earthquake': 0, 'cold': 0, 'other_weather': 0, 'direct_report': 1}\n"
     ]
    }
   ],
   "source": [
    "classification_labels = model.predict(['I am hungry'])[0]\n",
    "\n",
    "classification_results = dict(zip(df.columns[4:], classification_labels))\n",
    "print(classification_results)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a38ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model.best_estimator_, open('disaster_model1.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e9794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "220ad23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'related': 1, 'request': 1, 'offer': 0, 'aid_related': 1, 'medical_help': 0, 'medical_products': 0, 'search_and_rescue': 0, 'security': 0, 'military': 0, 'water': 0, 'food': 1, 'shelter': 0, 'clothing': 0, 'money': 0, 'missing_people': 0, 'refugees': 0, 'death': 0, 'other_aid': 0, 'infrastructure_related': 0, 'transport': 0, 'buildings': 0, 'electricity': 0, 'tools': 0, 'hospitals': 0, 'shops': 0, 'aid_centers': 0, 'other_infrastructure': 0, 'weather_related': 0, 'floods': 0, 'storm': 0, 'fire': 0, 'earthquake': 0, 'cold': 0, 'other_weather': 0, 'direct_report': 1}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "model1 = joblib.load(\"../disaster_model1.sav\")\n",
    "\n",
    "classification_labels = model1.predict(['I am hungry'])[0]\n",
    "\n",
    "classification_results = dict(zip(df.columns[4:], classification_labels))\n",
    "print(classification_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
